{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horses_Humans_Transfer_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "0e62741b-749b-41d6-ac19-0b60897dc942"
      },
      "cell_type": "code",
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-27 17:33:40--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.27.80, 2404:6800:4004:80a::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.27.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   110MB/s    in 0.8s    \n",
            "\n",
            "2019-04-27 17:33:41 (110 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "2eeab2e2-e2a9-4ecc-fd99-20c77c441ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8520
        },
        "outputId": "51a5fa20-9dd8-4fbb-c744-75a7fd8c9945"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "ee686fd8-1853-4b15-dc10-31553e838eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-27 17:35:31--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.197.208, 2404:6800:4004:800::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.197.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  92.9MB/s    in 1.5s    \n",
            "\n",
            "2019-04-27 17:35:33 (92.9 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-04-27 17:35:35--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.197.208, 2404:6800:4004:807::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.197.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  48.5MB/s    in 0.2s    \n",
            "\n",
            "2019-04-27 17:35:36 (48.5 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "3e9cb7af-6d22-4843-e3ba-2eefe08751fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir='/tmp/validation'\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "7837f963-5da8-496b-91d3-557ad5d97c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "c1f0d678-dae3-4104-ba11-785b58c9b7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1754
        }
      },
      "cell_type": "code",
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 183ms/step - loss: 0.0332 - acc: 0.9844\n",
            " - 15s - loss: 0.2597 - acc: 0.8861 - val_loss: 0.0332 - val_acc: 0.9844\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0015 - acc: 1.0000\n",
            " - 12s - loss: 0.1148 - acc: 0.9552 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 2.5481e-04 - acc: 1.0000\n",
            " - 12s - loss: 0.0501 - acc: 0.9786 - val_loss: 2.5481e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.0691 - acc: 0.9805\n",
            " - 12s - loss: 0.0632 - acc: 0.9786 - val_loss: 0.0691 - val_acc: 0.9805\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.0069 - acc: 0.9961\n",
            " - 12s - loss: 0.0344 - acc: 0.9883 - val_loss: 0.0069 - val_acc: 0.9961\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 1.8224e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.0385 - acc: 0.9883 - val_loss: 1.8224e-04 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 7.8218e-04 - acc: 1.0000\n",
            " - 12s - loss: 0.0543 - acc: 0.9805 - val_loss: 7.8218e-04 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.0506 - acc: 0.9844\n",
            " - 12s - loss: 0.0274 - acc: 0.9922 - val_loss: 0.0506 - val_acc: 0.9844\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 1.2796e-04 - acc: 1.0000\n",
            " - 12s - loss: 0.0378 - acc: 0.9903 - val_loss: 1.2796e-04 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.0063 - acc: 0.9961\n",
            " - 12s - loss: 0.0490 - acc: 0.9825 - val_loss: 0.0063 - val_acc: 0.9961\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.2709 - acc: 0.9648\n",
            " - 12s - loss: 0.0519 - acc: 0.9854 - val_loss: 0.2709 - val_acc: 0.9648\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.0342 - acc: 0.9922\n",
            " - 12s - loss: 0.0277 - acc: 0.9912 - val_loss: 0.0342 - val_acc: 0.9922\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.0914 - acc: 0.9844\n",
            " - 11s - loss: 0.0156 - acc: 0.9932 - val_loss: 0.0914 - val_acc: 0.9844\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.2239 - acc: 0.9688\n",
            " - 11s - loss: 0.0341 - acc: 0.9903 - val_loss: 0.2239 - val_acc: 0.9688\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.2655 - acc: 0.9648\n",
            " - 11s - loss: 0.0335 - acc: 0.9922 - val_loss: 0.2655 - val_acc: 0.9648\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.1352 - acc: 0.9766\n",
            " - 12s - loss: 0.0129 - acc: 0.9971 - val_loss: 0.1352 - val_acc: 0.9766\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.2104 - acc: 0.9727\n",
            " - 13s - loss: 0.0251 - acc: 0.9912 - val_loss: 0.2104 - val_acc: 0.9727\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.1385 - acc: 0.9727\n",
            " - 12s - loss: 0.0347 - acc: 0.9893 - val_loss: 0.1385 - val_acc: 0.9727\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.3162 - acc: 0.9570\n",
            " - 11s - loss: 0.0342 - acc: 0.9893 - val_loss: 0.3162 - val_acc: 0.9570\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.2671 - acc: 0.9648\n",
            " - 11s - loss: 0.0202 - acc: 0.9951 - val_loss: 0.2671 - val_acc: 0.9648\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.6101 - acc: 0.9414\n",
            " - 12s - loss: 0.0281 - acc: 0.9903 - val_loss: 0.6101 - val_acc: 0.9414\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.2958 - acc: 0.9648\n",
            " - 11s - loss: 0.0376 - acc: 0.9903 - val_loss: 0.2958 - val_acc: 0.9648\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.3559 - acc: 0.9531\n",
            " - 11s - loss: 0.0181 - acc: 0.9932 - val_loss: 0.3559 - val_acc: 0.9531\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.5292 - acc: 0.9492\n",
            " - 13s - loss: 0.0241 - acc: 0.9951 - val_loss: 0.5292 - val_acc: 0.9492\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.7151 - acc: 0.9375\n",
            " - 11s - loss: 0.0236 - acc: 0.9942 - val_loss: 0.7151 - val_acc: 0.9375\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 0.6828 - acc: 0.9414\n",
            " - 11s - loss: 0.0127 - acc: 0.9971 - val_loss: 0.6828 - val_acc: 0.9414\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.3048 - acc: 0.9570\n",
            " - 11s - loss: 0.0352 - acc: 0.9922 - val_loss: 0.3048 - val_acc: 0.9570\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 0.6903 - acc: 0.9453\n",
            " - 13s - loss: 0.0176 - acc: 0.9932 - val_loss: 0.6903 - val_acc: 0.9453\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.6210 - acc: 0.9492\n",
            " - 11s - loss: 0.0208 - acc: 0.9922 - val_loss: 0.6210 - val_acc: 0.9492\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.3941 - acc: 0.9531\n",
            " - 11s - loss: 0.0135 - acc: 0.9942 - val_loss: 0.3941 - val_acc: 0.9531\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.2927 - acc: 0.9609\n",
            " - 13s - loss: 0.0373 - acc: 0.9922 - val_loss: 0.2927 - val_acc: 0.9609\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.2098 - acc: 0.9844\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 11s - loss: 0.0087 - acc: 0.9990 - val_loss: 0.2098 - val_acc: 0.9844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "02386703-e27a-4728-a34c-b3347aef3d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQLjoO47jJBAu+o7jOAnE/wOmmCvnlHQBNAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}