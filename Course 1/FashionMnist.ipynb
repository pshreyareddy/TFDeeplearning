{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMnist.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yLqZSddDP9eY",
        "colab_type": "code",
        "outputId": "e39bf43f-85bf-49a4-f555-c8361ded4796",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hai\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "83NaCO2gP9en",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Fashion MNIST data is available directly in the tf.keras datasets API:"
      ]
    },
    {
      "metadata": {
        "id": "dclgjkICP9f-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e-v_u511P9gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calling load_data on this object will give you two sets of two lists, these will be the training and testing values for the graphics that contain the clothing items and their labels."
      ]
    },
    {
      "metadata": {
        "id": "XrEJUvWfP9gE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q34ZHxmxP9gJ",
        "colab_type": "code",
        "outputId": "ab999aeb-110f-401b-9c85-faa60a7ac91f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ekVmk8PzP9gS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All the values of numbers are between 0 and 255. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1, a process called 'normalizing'"
      ]
    },
    {
      "metadata": {
        "id": "ZL1UZ_FzP9gT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FI54-AP4P9gX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define Model"
      ]
    },
    {
      "metadata": {
        "id": "uPqItIhGP9gY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BatYX7e-P9gh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sequential**: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "**Flatten**: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
        "\n",
        "**Dense**: Adds a layer of neurons\n",
        "\n",
        "Each layer of neurons need an **activation function** to tell them what to do.\n",
        "\n",
        "**Relu** effectively means \"If X>0 return X, else return 0\" -- it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0]"
      ]
    },
    {
      "metadata": {
        "id": "-kbOElqDP9hs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build/Compile Model"
      ]
    },
    {
      "metadata": {
        "id": "-u-aqz5GP9hu",
        "colab_type": "code",
        "outputId": "e6f82881-8869-4408-cf68-d52775b43b0a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.5002 - acc: 0.8246\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.3768 - acc: 0.8637\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.3381 - acc: 0.8762\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.3165 - acc: 0.8832\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.2979 - acc: 0.8889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x79801fbf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "qZcc3ValP9iD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "XtjZV5YKP9iF",
        "colab_type": "code",
        "outputId": "f181f872-7e13-4f36-9bf9-87a05de80186",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 121us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3565299671888351, 0.8711]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "EUSzQudSP9iK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model is 87.11% accurate on test data"
      ]
    },
    {
      "metadata": {
        "id": "dfo_ArQKP9iM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exploration"
      ]
    },
    {
      "metadata": {
        "id": "M21fZcUCP9iN",
        "colab_type": "code",
        "outputId": "84bccda0-a0ee-4fe2-cefb-28e21083d1dd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7.3224513e-08 2.1255195e-08 1.6272395e-07 2.9288103e-07 4.5270767e-07\n",
            " 2.2786092e-02 3.7761365e-06 2.6003588e-02 1.2060289e-05 9.5119351e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dy2hkgYkP9iT",
        "colab_type": "code",
        "outputId": "96277227-6ee8-411f-de59-abf2d5f6fc7f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2SD-3HaP9ia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first image is classified as 9 (it has the highest probability in predictions)"
      ]
    },
    {
      "metadata": {
        "id": "hGbkwgK8P9ib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Impact of changing the dense layer neurons"
      ]
    },
    {
      "metadata": {
        "id": "lf84XSDUP9ie",
        "colab_type": "code",
        "outputId": "c2c5b1c4-9e33-4c1b-b931-cefa77f2e163",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 10s 1us/step\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 40s 670us/step - loss: 0.1832\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 36s 592us/step - loss: 0.0732\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 36s 592us/step - loss: 0.0487\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.0345\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 38s 630us/step - loss: 0.0266\n",
            "10000/10000 [==============================] - 1s 131us/step\n",
            "[1.6722790e-10 2.9785667e-11 4.0057038e-09 1.4995891e-06 3.0686703e-15\n",
            " 4.0820920e-09 8.2015077e-16 9.9999797e-01 1.8009041e-08 4.2743952e-07]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WXBLwx6gP9io",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training takes longer, but is more accurate"
      ]
    },
    {
      "metadata": {
        "id": "tLfVkv0GP9ip",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10.\n",
        "\n",
        "Ans: There isn't a significant impact -- because this is relatively simple data. For far more complex data, extra layers are often necessary."
      ]
    },
    {
      "metadata": {
        "id": "Khh5UXRTP9iq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Consider the impact of training for more or less epochs. Why do you think that would be the case?\n",
        "\n",
        "With 15 epochs -- we get a model with a much better loss than the one with 5 Try 30 epochs -- we see the loss value stops decreasing, and sometimes increases. This is a side effect of something called 'overfitting'."
      ]
    },
    {
      "metadata": {
        "id": "Ce1-JHjzP9ir",
        "colab_type": "code",
        "outputId": "fbdd9bab-2a7f-4fcb-d5ce-2de4418d70bb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=15)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1886\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 25s 408us/step - loss: 0.0802\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 25s 414us/step - loss: 0.0563\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0422\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0313\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.0286\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0241\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 25s 418us/step - loss: 0.0215\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0165\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 25s 421us/step - loss: 0.0189\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 25s 421us/step - loss: 0.0140\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 25s 419us/step - loss: 0.0182\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0150\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0121\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0130\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "[1.2079091e-18 1.1023008e-17 4.1822565e-15 3.9608864e-24 6.3607366e-21\n",
            " 1.4306081e-25 8.5298426e-28 1.0000000e+00 7.8682640e-19 4.2779387e-13]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EjSV5cf0P9iw",
        "colab_type": "code",
        "outputId": "5b83cd57-79d9-40fd-bae6-95cd89306679",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hai\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 28s 460us/step - loss: 0.1874\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 25s 411us/step - loss: 0.0790\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0562\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0412\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0334\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0266\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0239\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0227\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 25s 414us/step - loss: 0.0179\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 25s 418us/step - loss: 0.0187\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0156\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0177\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 27s 447us/step - loss: 0.0150\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0140\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 0.0149\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 22s 372us/step - loss: 0.0139\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0119\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 25s 421us/step - loss: 0.0147\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.0116\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 26s 433us/step - loss: 0.0129\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0110\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 25s 415us/step - loss: 0.0118\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 25s 417us/step - loss: 0.0123\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 29s 489us/step - loss: 0.0105\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 37s 611us/step - loss: 0.0110\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 29s 483us/step - loss: 0.0107\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0112\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0119\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0068\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0131\n",
            "10000/10000 [==============================] - 1s 82us/step\n",
            "[0.0000000e+00 1.2108882e-35 3.2485605e-36 8.8151644e-34 3.9465174e-37\n",
            " 4.1791149e-30 0.0000000e+00 1.0000000e+00 4.7185052e-35 1.4795205e-26]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M_r-UaL1P9i1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Impact of not normalizing data"
      ]
    },
    {
      "metadata": {
        "id": "nBxn3egFP9i2",
        "colab_type": "code",
        "outputId": "040f0cc6-9c09-4fab-e725-204046db4ef5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images\n",
        "test_images=test_images\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 11.4037\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 11.2471\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 10.6653\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 348us/step - loss: 10.1149\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 9.9163\n",
            "10000/10000 [==============================] - 1s 72us/step\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MlZUaw1PP9i-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using Call backs"
      ]
    },
    {
      "metadata": {
        "id": "NNQGk4uRP9i_",
        "colab_type": "code",
        "outputId": "735e7460-b3dd-4874-bd36-5e2c8817206f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.4770\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.3604\n",
            "\n",
            "Reached 60% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0xeb9cb92080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "_Zqv8ZASP9jF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Improving Computer Vision Accuracy using Convolutions\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VzHQ5bR9P9jK",
        "colab_type": "code",
        "outputId": "fb6912eb-d207-4c63-956c-0003882cc98a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.4992 - acc: 0.8237\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.3703 - acc: 0.8671\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.3301 - acc: 0.8796\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.3070 - acc: 0.8872\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.2938 - acc: 0.8917\n",
            "10000/10000 [==============================] - 1s 106us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BCsLpCBRP9jR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "accuracy is probably about 89% on training and 87% on validation\n",
        "Use convolutions to improve it.Convoulution narrow down the content of the image to focus on specific, distinct, details.\n",
        "\n",
        "In short, you take an array (usually 3x3 or 5x5) and pass it over the image.\n",
        "By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection. \n",
        "\n",
        "This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n",
        "\n",
        "Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3BMonOtsP9jS",
        "colab_type": "code",
        "outputId": "13501cf5-5e5c-45de-c478-028e8b90c1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 11s 188us/sample - loss: 0.4475 - acc: 0.8378\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2962 - acc: 0.8906\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2506 - acc: 0.9075\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2173 - acc: 0.9189\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.1937 - acc: 0.9269\n",
            "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2639 - acc: 0.9031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmq03hwMP9ja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUx40aTvRIxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The validation accuracy increase and then decreases.This is overfitting on the training data"
      ]
    },
    {
      "metadata": {
        "id": "WVH7c1vyRuMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualizing the Convolutions and Pooling\n",
        "This code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination."
      ]
    },
    {
      "metadata": {
        "id": "oHXeASvLRYmQ",
        "colab_type": "code",
        "outputId": "bb751d50-94e5-463d-e972-ce9b9849c29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eRos1fQkSBlu",
        "colab_type": "code",
        "outputId": "2bf52871-6b56-47db-e3df-548c829147eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=7\n",
        "THIRD_IMAGE=26\n",
        "CONVOLUTION_NUMBER = 1\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGOtaAAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "n7AwuTObSZUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1.Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time."
      ]
    },
    {
      "metadata": {
        "id": "RPoLtarmSgow",
        "colab_type": "code",
        "outputId": "95f98dad-839f-4562-b402-9a419a9d7a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1556 - acc: 0.9542\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0549 - acc: 0.9832\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0366 - acc: 0.9885\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0241 - acc: 0.9923\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0170 - acc: 0.9943\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0132 - acc: 0.9958\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0093 - acc: 0.9970\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0075 - acc: 0.9976\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0056 - acc: 0.9982\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0058 - acc: 0.9981\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 0.0537 - acc: 0.9861\n",
            "0.9861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "plAEFED4TJRf",
        "colab_type": "code",
        "outputId": "53f2baa0-3a7a-4f0b-8acb-3b9ca8cdf1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2704)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               346240    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 347,690\n",
            "Trainable params: 347,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I5D-V4ciTfyY",
        "colab_type": "code",
        "outputId": "54a83b99-5732-4d65-bc75-0c25a1e42be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.1362 - acc: 0.9585\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0461 - acc: 0.9863\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0299 - acc: 0.9906\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0176 - acc: 0.9943\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0115 - acc: 0.9962\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0097 - acc: 0.9969\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0068 - acc: 0.9976\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0059 - acc: 0.9980\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0046 - acc: 0.9984\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0040 - acc: 0.9986\n",
            "10000/10000 [==============================] - 1s 68us/sample - loss: 0.0549 - acc: 0.9867\n",
            "0.9867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uPfek6woTziX",
        "colab_type": "code",
        "outputId": "c809fc0d-8d2c-4bf5-b2bd-9ea2495e641b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10816)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               1384576   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,386,506\n",
            "Trainable params: 1,386,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DZciaI4T7px",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Add a new convolution layer."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4273800d-fa60-4c50-c364-5b79fc6781b9",
        "id": "BUJ7LMumUm6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1341 - acc: 0.9596\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0457 - acc: 0.9862\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0327 - acc: 0.9896\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 146us/sample - loss: 0.0241 - acc: 0.9925\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.0170 - acc: 0.9950\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0147 - acc: 0.9954\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0118 - acc: 0.9964\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0096 - acc: 0.9970\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0089 - acc: 0.9974\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0078 - acc: 0.9974\n",
            "10000/10000 [==============================] - 1s 64us/sample - loss: 0.0374 - acc: 0.9906\n",
            "0.9906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IQSgw5gFVlT5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Call backs "
      ]
    },
    {
      "metadata": {
        "id": "0xg9ySp-VdxZ",
        "colab_type": "code",
        "outputId": "ce3f9421-5b54-4ba4-e42d-9d90fb4bf0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.99):\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1334 - acc: 0.9592\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0435 - acc: 0.9864\n",
            "Epoch 3/10\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9902\n",
            "Reached 99% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0314 - acc: 0.9902\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 0.0273 - acc: 0.9905\n",
            "0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}